<div align='center'>
    从零开始的搜索系统学习笔记
</div>

<div align='right'>
    FesianXu 20210307 at Baidu intern
</div>

# 前言
笔者在百度实习的过程中，从零开始开始学习了一些关于信息搜索系统的知识，觉得受益匪浅，在此笔记，希望对读者有所帮助。**本文只是科普向，如有谬误请联系指出，本文遵守[ CC 4.0 BY-SA ](http://creativecommons.org/licenses/by-sa/4.0/)版权协议，转载请联系作者并注明出处，谢谢**。

$\nabla$  联系方式：

**e-mail**: FesianXu@gmail.com

**github**: https://github.com/FesianXu

**知乎专栏**: [计算机视觉/计算机图形理论与应用](https://zhuanlan.zhihu.com/c_1265262560611299328)

**微信公众号**：

![qrcode][qrcode]

-----



# 什么是搜索系统

信息之海浩瀚无穷无尽，要想从中有效地搜索出我们需要的信息，需要我们设计一套有效的信息搜索系统（information retrieval system）。我们期望这个系统能够对我们的检索请求进行响应，从海量信息中检索出能够解决我们疑问的，我们需要的信息。作为用户，我们对这个搜索系统的输入通常是一串字符串，我们称之为检索词（Query），而该系统会返回一系列的文档（Doc），这些文档既可以是网页，也可以是视频，音频等等多媒体信息。当然，从直观上说，我们当然希望返回的文档和我们用户潜在的检索意愿越相近越好，此处的相近可以简单理解为Query和Doc的相关性。相关性是信息搜索系统最基础的指标，从最朴素的角度来说，我们搜索系统返回的Doc可以按照相关性降序排序。当然，**相关性**并不是搜索系统的唯一指标，作为一款合格的商业搜索系统，我们还需要考虑检索出的Doc的**时效性**，信息具有时效性，我们当然希望检索出来的信息是最新的。同时，我们希望检索出的Doc具有**权威性**，比如对于一些专业知识领域的检索，医学，法律，电子技术等等，我们希望检索出来的Doc是来自于权威网站或者权威作者的。在一些垂直信息搜索领域，比如图片搜索，视频搜索等，我们还希望搜索出来的结果尽可能是高清的，这些可以归在Doc的**质量**上。为了公司产品的运营需求，使得搜索结果符合法律法规，我们通常还需要对检索Doc进行**违法违规内容打压**，比如涉黄涉暴的敏感信息必须得到打压。在基于Query和Doc的诸多考虑之后，我们需要量化这里指标，比如对相关性，权威性，时效性，质量，信息打压等等进行量化，然后用模型进行多指标打分。根据这个打分对所有的Doc进行降序排序，将整个排序结果返回呈现给用户，这就完成了一次检索过程。这个过程并不完整，我们通常还会考虑点击模型，对每个Doc的用户点击数量进行预测，结合这些指标进行**上层排序**。

当然这是一个极度简化了的信息检索过程，在更为实用的系统中，为了实现检索的准确，全面，高效等，需要更为细致的算法策略设计和架构设计保驾护航。总体来说，大多数信息检索系统可以分为以下几个阶段：

1. 信息爬取：我们通过大规模的爬虫，从各个网站中爬取各种连接，然后将其储存到数据库中，为了保证检索的高效，我们按照爬取网页的质量可以将整个数据库进行分层次排序，将检索流量尽可能的往着最高质量的资源上引导，这样我们就能在保证结果高质量高相关的情况下，又能保证检索过程的高效完成。

1. Query分析： 为了实现Query和Doc的相关性匹配，首先我们要能够从Query中分析用户的潜在检索需求，这一点和自然语言处理（NLP）密切相关，因为Query通常是以字符串的形式体现的。Query分析包括了很多东西，包括对Query的切词，纠错，补充，需求识别，Query改写等等。

2. 信息召回（information recall）：指的是从海量的，数以亿计的数据中找到和Query分析后的结果相关性较为接近的结果。在这个阶段需要控制召回doc的粒度，如果召回doc过多则容易给之后的doc排序造成性能影响；如果召回doc过少，则很容易导致漏掉某些相关的doc，也既是召回不全面。通常我们用召回率和精准率衡量召回结果。
3. 排序（doc rank）：在召回了充分的doc之后，就可以对这些doc进行排序了，排序的基本要求就是query-doc相关性，同时需要满足其他各种商业，运营的要求。排序按照排序的粒度，可以分为粗排和精排。



# 信息爬取

信息爬取通过网络爬虫（Web Spider）在互联网上进行海量的信息搜集。信息搜集是信息检索的基础，如果没有采集到足够的信息资源就谈不上信息检索，因此网络爬虫的高质量运行是信息引擎的基础。通常网络爬虫需要考虑很多问题，比如如何爬取高质量的页面，如何避免重复爬取页面，如何并行地高效爬取页面等等。当然并不是所有资源都是可以爬取的，网站的`robots.txt`协议从道德的角度规定了该站点信息的可爬取性。笔者对爬虫并不了解，因此就不展开讨论了。一旦爬虫爬取到了足够的信息之后，就为信息检索提供了基石，然而大型商业检索引擎每天都能爬取海量的信息，这些信息中并不是每个都是高质量，强时效性的，意味着我们可以通过**信息分层**的方法，去组织不同质量的资源，以保证检索质量的同时提高整个信息检索的效率。通常的信息资源分层呈现金字塔型，如Fig 2.1所示，通常会将高质量，高时效性的资源组成一个库层，这个库层通常数量较少，但是却可以满足大部分用户的检索需求。在一次信息检索过程中，首先会在高质量库层中进行信息召回，如果没有召回到足够的资源，那么会穿透到第二层库层，该库层信息资料较低，或者时效性较差，数量级可能是第一层的十倍到百倍。如果前两层都不能检索到足够的资源，那么会穿透到最底下的海量资源库，数量级可能是之前库层的十倍到百倍之间，在海量资源库中检索到的结果将会作为兜底进行传递。

![hierachi_layers][hierachi_layers]

<div align='center'>
    <b>
        Fig 2.1 通常搜索引擎会将检索到的资源进行分层，在每次检索时，首先查找数量较少质量较高的库层，如果没有检索到足够满意的结果再穿透到下一层的库层。
    </b>
</div>

# Query分析

检索系统可以分为用户检索端（Query端，Q端）和文档资源端（Doc端，URL端，U端）。在用户检索端一侧，我们要求能够系统能够理解用户的真实检索需求，而用户在信息检索系统中，通常用自然文字去描述其检索需求。这就意味着我们需要让机器去理解用户的自然文字表述，并且从中去挖掘用户的真实检索需求。我们用过百度都知道，在搜索过程中我们会用千奇百怪的方式去表达一个简单的需求，语序，语法句法，错别字，中英文混搭，各种奇怪的情况都可能在用户query中出现。因此在检索系统中，如何对用户query进行分析非常重要，通常query分析分为切词，纠错，扩充，需求识别等等。



# 信息召回







![multi_term_chains][multi_term_chains]



# 相关性



## 基础相关性



散弹命中，QT匹配



## 语义相关性









# 信息排序





## 粗排





## 精排





# Learn To Rank，LTR



## pointwise训练



## pairwise训练





## listwise训练



 





# Reference











[qrcode]: ./imgs/qrcode.jpg
[multi_term_chains]: ./imgs/multi_term_chains.png

[hierachi_layers]: ./imgs/hierachi_layers.png






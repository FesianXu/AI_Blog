<h1 align = "center">二类分类器扩展多类分类器</h1>

## 前言
**本文参考周志华老师的《机器学习》一书中关于二类分类器和多类分类器的讨论，探讨二类分类器如何扩展为多类分类器的几种常见方法。**
**如有谬误，请联系指正。转载请注明出处。**
*联系方式：*
**e-mail**: `FesianXu@163.com`
**QQ**: `973926198`
**github**: `https://github.com/FesianXu`

-----

# 二类VS多类
　　二分类和多分类，从名字上就可以得知其含义。**二分类**：其目标类别有两个，多分类：其目标类别有多个。
　　我们常见的很多分类器是二分类的，比如著名的SVM，Logistic回归，也有很多天生就可以是多分类的，比如神经网络，决策树及其变种，KNN等。这些二分类模型生下来就是进行二分类的，对于多分类问题不能直接套用，而是需要扩展。假设一个多分类任务有$n$个类$C_1,C_2,\cdots,C_n$，对此的二分类扩展基本策略就是“拆解法”，将这个多分类任务拆分为多个二分类任务，然后由**每一个二分类任务投票**得到最终的多分类结果。经典的拆分策略分为：**1对1（one vs one, OvO）, 1对其余(one vs rest, OvR), 多对多(many vs many, MvM)**。
  
## 一对一， One vs One
　　对于$n$个类，对于其中的每两个类$C_i$和$C_j$建立一个分类器$f_{ij}$，一共需要设置$n(n-1)/2$个分类器，其最后的分类结果用投票的方法得出。
![ovo][ovo]

## 一对其余，One va Rest
　　对于OvR，则是将其中的一个类$C_i$作为正类，其余的类作为负类，进行训练，对于$n$个类，只需要$n$个分类器即可。在测试过程中，如果仅有一个类被预测为正类，则这个就是最终的分类结果，如果有多个类被预测为正类，则考虑置信度进行判断。
![ovr][ovr]

> **可以看出OvR只需要训练$n$个分类器，而OvO需要$n(n-1)/2$个分类器，因此OvO的储存空间和测试时间都会比OvR的要高，但是因为训练过程中OvR每次都要利用n个类的样本，而OvO只需要两个类的样本，因此OvR的训练时间要比OvO的长，至于预测能力，在大多数情况下两者类似。**
> 《机器学习》——周志华

## 多对多，Many vs Many





[ovo]: ./imgs/ovo.png
[ovr]: ./imgs/ovr.png
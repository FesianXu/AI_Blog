<h1 align = "center">机器学习性能评判标准</h1>

## 前言
**
衡量一个机器学习算法的优劣有许多指标可以参考，对于不同任务的不同算法需要采用不同的指标进行衡量而不能一概而论，正如没有免费午餐定律所揭示的，没有任何一个算法可以在所有数据集上表现良好，因此需要用合适的性能评判指标去选择合适的机器学习模型。这里浅谈一些评判指标，部分素材来自《机器学习》 周志华。
**

**如有谬误，请联系指正。转载请注明出处。**
*联系方式：*
**e-mail**: `FesianXu@163.com`
**QQ**: `973926198`
**github**: `https://github.com/FesianXu`


----

# 采用不同学习器性能评判的必要性
　　正如前言所说，对于一个特定的任务需要一个特定的性能评判标准，那为什么不同任务的评判标准不能通用呢？比如说经常用的误差率$error=N_{wrong}/N_{total}$不是能很好的表示性能吗？为什么要多此一举呢？
　　让我们假设一个场景：
> 在医疗中，患癌症是一个小概率事件（先验概率小），而正常才是一个大概率事件，假设一个区域的人经过统计可以知道患癌的人和不患癌的人比例为1：99。

　　那么如果单纯将任何一个新的病人（未知其患病情况）都看成是正常的，那么如果按照误差率来说只有1%，然而，这样就失去预测的意义。因此，**误差率**或者说是**准确率**对于这种高度不平衡的样本的任务不适合，需要用更加适合的评判标准进行评估。
  
# 不同的性能评估指标
![Evaluation]

## 混淆矩阵(confusion matrix)
　　混淆矩阵在分类问题中，特别是多分类问题中应用广泛，其一般形式如：
![ConfusionMatrix]  
其中对角线的表示正确分类的，其余的都是错分类的。当只有两类的时候，退化为：
![BinaryConfusionMatrix]
其中，**FP为误报样本**，**FN为漏报样本**。

## Accuracy 准确率
　　就是一开始提到的误差率的补数，为：
$$
Accuracy = \frac{TP+TN}{TP+TN+FP+FN}　 (Binary　Class)
$$
$$
Accuracy = Tri(M)/\sum_i\sum_jM_{ij}　 (Multiple　Class)
$$
　　不适合用于不平衡的先验分布的数据集，如患病人群，网络攻击等。
  
## Precision 精确率，查准率
　　Precision用于评估**检索出的信息中有多少是用户感兴趣的**，也被称为查准率。
$$
Precision = \frac{TP}{TP+FP}　(Binary　Class)
$$
$$
Precision(j)_N = \frac{M_{j, j}}{\sum_{i=1}^N M_{i,j}}　(Multiple　Class)
$$

## Recall 召回率，查全率
　　用于评估**用户感兴趣的信息中有多少被检索出来了。**
$$
recall = \frac{TP}{TP+FN}　(Binary　Class)
$$
$$
Precision(i)_N = \frac{M_{i, i}}{\sum_{j=1}^N M_{i,j}}　(Multiple　Class)
$$

## F1 measure
$$
\frac{2}{F_1} = \frac{1}{Precision}+\frac{1}{Recall}
$$


[Evaluation]: ./imgs/Evaluation.png
[ConfusionMatrix]: ./imgs/ConfusionMatrix.png
[BinaryConfusionMatrix]: ./imgs/BinaryConfusionMatrix.png

# 备忘录
《深度学习》 GoodFellow, 中国工信出版集团， 人民邮电出版社 第一版 一书的小笔记

1. **page 123**， cpt 6.4 
>  更深层的网络通常能够对每一层使用更少的单元数和更少的参数，并且经常容易泛化到测试集，但是通常也更难以优化。

2. **page 123**, cpt 6.4.1 
>  万能近似定理可以适用于众多激活函数，包括ReLU

3. **page 125**， cpt 6.4.1
>  在相同的参数数量的前提下，往往深层模型有着更好的泛化表现，因为其有着一个隐式假设（信念），既是**该目标函数应该由许多更简单的函数复合在一起而得到，这可能导致学习由更简单的表示所组成的表示（例如由边所定义的角）或者学习具有顺序依赖步骤的程序（例如，首先定位一组对象，然后分割他们，之后识别他们）。**

4. **page 142**， cpt 7.1
>  我们通常只对权重做惩罚而不对偏置做正则惩罚（`实验的确如此`），正则化偏置参数可能会导致明显的欠拟合。

5. 
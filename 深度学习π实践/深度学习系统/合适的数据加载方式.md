<div align='center'>
    《深度学习π实践》 合适的数据加载方式
</div>

<div align='right'>
    FesianXu 2020.6.19 at Tencent internship
</div>

# 前言

本文介绍了一种在深度学习系统搭建中效率较高的数据加载方式，笔者称之为“面向索引的数据加载（index-oriented data loading）”，通过这种方式，我们可以用很低的成本管理数据集的版本，配合异步并行多线程加载，我们可以实现高效的数据加载，本博文的配套项目见[1]，该项目的数据加载部分就是通过该思路进行设计的。如有谬误请联系指出，写作不易，转载请注明出处，并且通知笔者，谢谢。

$\nabla$ 联系方式：
**e-mail**: [FesianXu@gmail.com](mailto:FesianXu@gmail.com)
**QQ**: 973926198
github: https://github.com/FesianXu

----



# 模型，数据，算法同样重要

在进行深度学习算法系统搭建的时候，我们需要时刻谨记的是，数据，模型，算法三者同样重要。这三者同样重要的观点在[2]文章中已经阐述过了，因此本文也不进行累述。有一句话说得很好：

> 数据决定了学习系统的上限，模型和算法想办法去达到这个上限。

通常来说，我们的算法和模型都是以代码的形式储存的，而数据通常是二进制的图像，文本或者语音等，如果我们有用git进行版本管理的习惯的话（这是个好习惯），我们知道，git适用于管理文本型的数据，比如代码就非常适合，因为其可以比较不同版本之间的差异性，所以我们都会用git去做模型和算法代码的版本管理，以便于可以复现不同时期的版本代码的效果。然而，我们知道数据也很重要，我们是否需要对数据进行版本管理呢？显然也是需要的，但是git这类型的版本管理并不适合于管理数据集，如果考虑使用数据库的话，我们的图片这些属于是`object`类型的数据，并不适合直接管理。

而且，不仅仅是数据的版本管理问题，我们在深度学习系统训练或者测试过程中需要加载数据，如果把海量的数据都一股脑加载到内存中显然是很傻的，一是内存可能撑不住那么大的数据量，二是刚开始加载时速度会很慢。我们可以考虑用生成数据集文件索引的方式，配合并行的数据加载器，我们可以实现一个高性能，而且可以管理数据版本的数据加载器。



# 面向索引的数据加载

这个方法其实很朴素简单，我们的原始数据集样本还是存储在磁盘上，我们在开始训练/测试时，只需要加载一个数据索引表，这个表记录着所有训练样本和测试样本的id，在需要样本本体进行处理时，再根据id在磁盘上动态加载样本。以`pytorch`的数据加载过程为例子，我们有：

```python
class LipnetDataset(Dataset):
    def __init__(self, tmode, length=None, data_augment=False):
        assert tmode in ('train', 'eval', 'test', 'whole_train')

        self._tmode = tmode
        self._length = length
        if tmode in ('train', 'eval', 'whole_train'):
            self._datapath = gc.train_img_datapath
            if tmode == 'train':
                self._dataindex = gc.train_index
            elif tmode == 'eval':
                self._dataindex = gc.eval_index
            else:
                self._dataindex = gc.whole_train_index
        else:
            self._datapath = gc.test_img_datapath
            self._dataindex = gc.test_index
        self.len_dataset = len(self._dataindex)
        self.data_augment = data_augment
        self.trans = transforms.Compose([
                                transforms.ToPILImage(),
                                transforms.Resize((gc.pic_height, gc.pic_width)),
                                transforms.ToTensor(),
                                transforms.Normalize([0, 0, 0], [1, 1, 1]) 
                            ])

        if data_augment and tmode in ('train', 'whole_train'):
            self.data_augment_transfer = iaa.Sequential([
                #  iaa.Fliplr(0.5), # horizontal flips
                #  iaa.ContrastNormalization((0.75, 1.5)),
                #  iaa.Affine(
                #     scale={"x": (0.8, 1.2), "y": (0.8, 1.2)},
                #     translate_percent={"x": (-0.2, 0.2), "y": (-0.2, 0.2)},
                #     rotate=(-10, 10),
                #     shear=(-2, 2)
                # ),
                 iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5),
                
            ], random_order=True)
            # data augmentation
        else:
            self.data_augment_transfer = None

    def __len__(self):
        if not self._length:
            return self.len_dataset
        return self._length
    
    def __getitem__(self, index):
        if self._tmode in ('train', 'eval', 'whole_train'):
            hashname, label = self._dataindex[index]
        else:
            hashname = self._dataindex[index]

        foldername = self._datapath+hashname+'/'
        imglen = len(os.listdir(foldername))
        files = [os.path.join(foldername, ('{}' + '.jpg').format(i)) for i in range(1, imglen+1)]
        files = list(filter(lambda path: os.path.exists(path), files))
        frames = [cv2.imread(file) for file in files ] 
        frames_ = [cv2.cvtColor(img, cv2.COLOR_BGR2RGB) for img in frames]
        length = len(frames_)
        vlm = torch.zeros((gc.nchannels, gc.seq_max_lens, gc.pic_height, gc.pic_width))
        
        if length <= gc.seq_max_lens:
            for i in range(length):
                vlm[:, i] = self.trans(frames_[i])
        else:
            # downsample
            for i in range(gc.seq_max_lens):
                vlm[:, i] = self.trans(frames_[i])
        
        if self.data_augment_transfer:
            vlm = vlm.permute(1,2,3,0).data.cpu().numpy()
            vlm = self.data_augment_transfer(images=vlm)
            vlm = torch.tensor(vlm).permute(3, 0, 1,2)

        if self._tmode in ('train', 'eval', 'whole_train'):
            return {'volume': vlm, 
                    'label': torch.LongTensor([int(label)]), 
                    'length': length,
                    'hashname': hashname}
        else:
            return {'volume':vlm,
                    'hashname':hashname,
                    'length': length}
```







# Reference

[1]. https://github.com/FesianXu/LipNet_ChineseWordsClassification

[2]. https://blog.csdn.net/LoseInVain/article/details/105644994






<div align=center>
<font size="6"><b>深度学习中损失平面与泛化性能的探究</b></font>
</div>

[TOC]

****

# 前言

**本文将基于文章[2]中谈到的损失函数平面与泛化性能之间的讨论进行一些探讨，对博客[1]和[3]的内容进行一些扩展，本文很多引用论文[2]的实验结果，强烈建议大家去翻看原文，受益匪浅。**

**如有谬误，请联系指出，谢谢。**

*联系方式：*

**e-mail**: `FesianXu@163.com`

**QQ**: `973926198`

**github**: `https://github.com/FesianXu`



****

#  损失函数的可视化

在深度学习中，我们一般都是需要设置一个损失函数，用其来描述我们的目标任务，并且对其进行最优化，一般是最小化处理的。正如我们在[1]中讨论的，因为深度学习中的网络通常具有海量的参数，因此通常都是看成是一个在极其高维的情况下的最值搜索问题。为了研究不同最优化方法在深度学习中的有效性，通常是需要对其损失函数平面（以下简称**损失平面**）进行可视化的，如下图所示。但是我们知道，人类视觉只能感受到3维空间的信息，因此当参数超过3时便变得难以可视化。因此一些学者提出了对损失平面的切片进行可视化的方法，如[4]中提到的1维线性插值切片和2维等高线绘制等，其中2维等高线绘制方法我们在博客[1]中已经有简单介绍了，这里就不对其进行累述了。

![optimizer][optimizer]







****

# Reference

[1]. [损失函数的可视化——浅论模型的参数空间与正则](https://blog.csdn.net/LoseInVain/article/details/83473975)

[2]. Li H, Xu Z, Taylor G, et al. Visualizing the loss landscape of neural nets[J]. arXiv preprint arXiv:1712.09913, 2017.

[3]. [深度学习debug沉思录](https://blog.csdn.net/LoseInVain/article/details/83021356)

[4]. Ian J Goodfellow, Oriol Vinyals, and Andrew M Saxe. Qualitatively characterizing neural network
optimization problems. *ICLR*, 2015.





[optimizer]: ./imgs/optimizer.gif
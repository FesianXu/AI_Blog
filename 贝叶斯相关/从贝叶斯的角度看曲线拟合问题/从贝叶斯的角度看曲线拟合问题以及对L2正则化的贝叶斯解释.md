<h1 align = "center">从贝叶斯的角度看曲线拟合问题以及对L2正则化的贝叶斯解释</h1>

## 前言

**在以前文章中，我们讨论过[《概率学派和贝叶斯学派的区别》](https://blog.csdn.net/loseinvain/article/details/80499147)和[《 <机器学习系列> 线性回归模型》](https://blog.csdn.net/loseinvain/article/details/78245665)，现在来看很多曲线拟合模型都是基于频率学派的方法进行学习的，这里简单介绍下基于贝叶斯学派的曲线拟合问题。**

**如有谬误，请联系指正。转载请注明出处。**

*联系方式：*
**e-mail**: `FesianXu@163.com`
**QQ**: `973926198`
**github**: `https://github.com/FesianXu`
**code**: 

*******************************************************

# 贝叶斯曲线拟合
这里的曲线指的是多项式曲线（polynomial curve）[^1]，如下图所示：

![poly_curve][poly_curve]

一般来说，概率学派按照最小化平方和误差函数，如下所示，来进行参数的学习的。
$$
\mathcal{T}_{\theta} = \arg \min_{\theta} \mathcal{L}(\hat{y},y) \\
\hat{y}_j = \sum_{i=0}^N \theta_i x_{(i,j)}^{i} = y(x;\theta)\\
\mathcal{L}(\hat{y}, y) = \dfrac{1}{2}||\hat{y}-y||^2
\tag{1.1}
$$
$x_{(i,j)}$表示第$j$个样本的第$i$维数据值。

****

而在贝叶斯学派的眼中，我们通过多项式模型预测出来的并不是一个单纯的数字，而是一个分布，一般来说我们将其假设为是一个均值为$t$（也就是预测目标值），方差为$\sigma^2$（$\beta=\dfrac{1}{\sigma^2}$，$\beta$称之为精确度precision），因此预测出来的分布如下式所示：
$$
p(t|x, \textbf{w}, \beta) = \mathcal{N} (t|y(x, \textbf{w}), \beta^{-1})
\tag{1.2}
$$

图像看起就更加直观了：

![bayesian][bayesian]

可以看出，对于某一个预测，其为一个分布（蓝色线），其中预测的均值的预期就是观察值点A，可以看出，参数$\beta$决定了其置信范围$2\sigma$的大小。如果采用频率学派中的观点，那么就会采用**极大似然法**进行参数估计。似然函数如下所示：
$$
p(\textbf{t}|\textbf{x},\textbf{w}, \beta) = \prod_{i=0}^N \mathcal{N} (t_n | y(x_n, \textbf{w}), \beta^{-1})
\tag{1.3}
$$
为了计算方便转化为对数似然后，有：
$$
\ln p(\textbf{t}|\textbf{x},\textbf{w}, \beta) = -\dfrac{\beta}{2} \sum_{n=1}^N \{y(x_n, \textbf{w})-t_n\}^2 + \dfrac{N}{2}\ln \beta - \dfrac{N}{2} \ln (2\pi)
\tag{1.4}
$$






# Reference
1. Bishop 《Pattern Recognize and Machine Learning, PRML》
2. [《概率学派和贝叶斯学派的区别》](https://blog.csdn.net/loseinvain/article/details/80499147)
3. [《 <机器学习系列> 线性回归模型》](https://blog.csdn.net/loseinvain/article/details/78245665)





[^1]: A curve obtained by fitting polynomials to each ordinate of an ordered sequence of points. 指的是用多项式函数$f(\textbf{X}; \theta)=\sum_{i=0}^N \theta_i x_i^{i}, \textbf{X} \in \mathbb{R}^N$。其中如果指数全部变为1而不是$i$，则退化为线性回归。


[poly_curve]: ./imgs/poly_curve.png
[bayesian]: ./imgs/bayesian.png



<h1 align = "center">概率学派和贝叶斯学派的区别</h1>

## 前言

**对于一个数学模型来说，最主要的莫过于根据观察到的数据进行模型的参数估计了，而概率学派和贝叶斯学派对于这个参数估计有着不同的做法，接下来我们讨论下。**

**如有谬误，请联系指正。转载请注明出处。**

*联系方式：*
**e-mail**: `FesianXu@163.com`
**QQ**: `973926198`
**github**: `https://github.com/FesianXu`
**code**: 

*******************************************************

# 概率派和贝叶斯派的区别
对于一个问题，从概率派和贝叶斯派看起来是完全不一样的，其最主要的区别就是对于一个问题中模型参数的“信仰”：

* 对于频率派学者来说，一个模型中的参数是“固定”的，而数据是在分布中随机采样的。我们要**重点**理解这个固定，这里指的固定意思是

> 对于一个模型或者也可说一个分布中的参数，我们相信它是固定不变的，而我们观察（采样）到的数据是这个分布中的一个独立同分布样本。也就是说，我们相信这个分布的参数不管你怎么采样，根据参数对其的估计都应该是不会变的，They remain constant!如果根据数据估计出来的参数和真实模型不符合，只可能是引入了噪声而已。**在这个观点中，模型参数才是上帝，数据为之服务。**


* 对于贝叶斯派学者来说，我们观察到的数据才是“固定”的，而我们的模型的参数才是在一直变化的。我们不停地观察数据，估计出来的模型参数就可能一直的变化。不仅如此，我们对于这个模型的参数可能会有一个最初始的信仰，称之为**先验假设**，一旦设置后了之后，我们就可以听由观察到的数据指导模型参数更新了。在这种观点中，我们的模型参数不再是一个参数，而是一个分布了。一般来说，对于贝叶斯派，有公式：
$$
P\{\theta|D\} = \dfrac{P\{D|\theta\}P\{\theta\}}{P\{D\}}
\tag{1.0}
$$
其中$P\{\theta|D\}$称为后验概率，指的是由观察数据和先验假设推测出来的参数分布，而$P\{\theta\}$称之为先验分布，指的是对于参数的专家知识或者假设而引入的知识，可以指导参数$\theta$的学习，而$P\{D|\theta\}$称之为似然函数，指的就是由于观察数据导致的参数更新。

****

我们举个投硬币的例子也说明下这两者区别：
> Question：现在我们有一个硬币，假设朝向正面的几率为$p$，朝向反面的几率为$1-p$，这个$p$是未知的，现在为了估计$p$，投掷了14次，其中有10次朝向正面，问再投掷两次，都朝向正向的概率为多少。

在传统的概率派解答中，因为相信这个模型的参数是固定的，所以很容易知道$p=\dfrac{10}{14}=0.714$，因此在后面投掷两次的过程中，假设都是独立过程，那么
$$
P\{HH|data\}=p^2=0.51
\tag{1.1}
$$

****

而在贝叶斯派眼中，问题就没有那么简单了，我们相信参数$p$不是简单的一个参数，而应该是一个随机变量，服从一个分布，那么我们就需要用观察到了的数据$data$去估计这个参数$p$的分布，利用贝叶斯公式有：
$$
P\{p|data\} = \dfrac{P\{data|p\}P\{p\}}{P\{data\}}
\tag{1.2}
$$
因为在已知观察中，$data$是固定的，所以$P\{data\}=constant$是一个常数，不妨忽略它，有：
$$
P\{p|data\} \propto P\{data|p\}P\{p\}
\tag{1.3}
$$

有:
$$
P\{data|p\} = C_{14}^{10} p^{10}(1-p)^{4}
\tag{1.4}
$$
参数$C_{14}^{10}$可以忽略，现在对于先验假设$P\{p\}$进行假设，一般来说，我们希望这个假设是一个共轭先验（conjugate prior）[^1]。
这里用Beta分布作为硬币参数的先验假设，

$$
Beta(p;a,b)=\dfrac{\Gamma(a+b)}{\Gamma(a) \cdot \Gamma(b)} \cdot p^{a-1}(1-p)^{b-1}
\tag{1.5}
$$
其中伽马函数$\Gamma(\cdot)$定义为:
$$
\Gamma(x) = \int_{0}^{+\infty} t^{x-1}e^{-t} \rm dt
\tag{1.6}
$$

Beta分布有两个控制参数a和b，不同的a和b其CDF的形状差别很大：
![gamma][gamma]

****

在这个先验假设下，我们有：
$$
P\{p\} = Beta(p;a,b)
\tag{1.7}
$$
同样的，因为$\dfrac{\Gamma(a+b)}{\Gamma(a)}$是常数项，忽略所以有：
$$
\begin{align}
P\{p|data\} &\propto p^{10}(1-p)^{4} \cdot p^{a-1} (1-p)^{b-1} \\
& \propto p^{10+a-1}(1-p)^{4+b-1}
\end{align}
\tag{1.8}
$$

为了让
$$
\int_{0}^{+\infty} p\{p|data\} \rm dp = 1
\tag{1.9}
$$
需要拼凑系数，可知道系数为（**这里不是特别懂**）
$$
\dfrac{\Gamma((10+a)+(4+b))}{\Gamma(10+a) \cdot \Gamma(4+b)} = \dfrac{1}{B(10+a,4+b)}
\tag{1.10}
$$
其中$B(x,y)$为Beta函数，$B(x,y) = \dfrac{\Gamma(x) \Gamma(y)}{\Gamma(x+y)}$

于是最终有参数$p$的概率分布为:
$$
P\{p|data\} = Beta(p;a+10, b+4)
\tag{1.11}
$$
如果我们对$p$毫无先验可言，那么可以令$a=b=0$，这个时候的计算结果就和频率学派的一模一样，但是如果我们自认为对这个硬币的参数$p$有所了解，但是又不是完全了解，比如说我们知道这个先验应该是一个均匀分布的（也就是正面和反面都应该是0.5的，这个应该是最朴素和直观的假设了。），而均匀分布是Beta分布的一个特例，我们可以令$a=b=1$，这个时候有：
$$
P\{p|data\} = Beta(p;11,5)
\tag{1.12}
$$
图像如：

<div align="center">![gamma_2][gamma_2]</div>

可以看到因为引入了这个朴素的假设，使得$p$变成了一个中心在$p=0.7$附近的钟形分布，这个时候就发现了和频率派的区别：**我们的参数p是一个分布，而不只是一个数值而已。**

****

有了$P\{p|data\}$，我们回归原问题，求:
$$
P\{HH|data\} = \int_{0}^{1} P\{HH|p\} P\{p|data\} \rm dp
\tag{1.13}
$$
这里用积分的原因很简单，就是因为我们的p是一个分布，其值从0到1，因此需要用积分。
这里进行两个假设：
1. 投掷硬币每一次都是独立无关的。
2. 在这接下来的两个投掷过程中我们不更新$P\{p|data\}$

所以有：
$$
P\{HH|p\} = [P\{H|p\}]^2 = p^2
\tag{1.14}
$$
所以有:
$$
P\{HH|data\} = \int_{0}^{1} p^2 \cdot P\{p|data\} \rm dp
\tag{1.15}
$$
所以有:
$$
\begin{align}
P\{HH|data\} &= \dfrac{1}{B(10+a,4+b)} \int_{0}^{1} p^{(10+a-1)+2} (1-p)^{4+b-1} \\
&= \dfrac{B(10+a+2,4+b)}{B(10+a, 4+b)}
\end{align}
\tag{1.16}
$$

同样假设$a=b=1$则有$\dfrac{B(13,5)}{B(11, 5)}=0.485$，从这里就看出了频率学派和贝叶斯学派的区别。


## 总结

频率学派和贝叶斯学派的方法优缺点概况：

* 频率学派是目前深度学习中最常使用的指导思想，但是要想其效果好，必须基于数据量巨大的情况下，否则很难估计出一个好的参数。（因为其不引入任何先验假设，只能从大数据中学习得到。）
* 贝叶斯学派的方法可以应用在数据量小的情况下，而且方便引入各种专家知识和先验知识，有些场景中表现更为优越。

实际上，频率学派和贝叶斯学派有着千丝万缕的关系，不可割裂看待，也没有孰优孰劣。



# Reference
1. Bishop 《Pattern Recognize and Machine Learning, PRML》
2. [《Are you a Bayesian or a Frequentist? (Or Bayesian Statistics 101)》](http://www.behind-the-enemy-lines.com/2008/01/are-you-bayesian-or-frequentist-or.html)
3. [《Bayesian and frequentist reasoning in plain English》](https://stats.stackexchange.com/questions/22/bayesian-and-frequentist-reasoning-in-plain-english)
4. [《先验概率、后验概率以及共轭先验》](https://blog.csdn.net/baimafujinji/article/details/51374202)


[^1]: 后验概率分布（正⽐于先验和似然函数的乘积）拥有与先验分布相同的函数形式。这个性质被叫做共轭性（Conjugacy）。共轭先验（conjugate prior）有着很重要的作⽤。它使得后验概率分布的函数形式与先验概率相同，因此使得贝叶斯分析得到了极大的简化


[gamma]: ./imgs/gamma.png
[gamma_2]: ./imgs/gamma_2.png